import os
from dotenv import load_dotenv
from openai import OpenAI


# Initialize OpenAI client with API key from environment
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def generate(prompt: str, temperature: float = 0.2, model: str = "gpt-4") -> str:
    """
    Sends the tool planning prompt to OpenAI Chat Completions API and returns
    the raw LLM response.

    Args:
        prompt (str): The full planner prompt including tool specs and user instruction.
        temperature (float): Controls response randomness.
        model (str): Model to use (default: gpt-4).

    Returns:
        str: Tool JSON plan generated by OpenAI LLM.
    """
    try:
        response = client.chat.completions.create(
            model=model,
            temperature=temperature,
            messages=[
                {
                    "role": "system",
                    "content": "You are a precise tool-calling agent. Return only a JSON array of tool calls.",
                },
                {"role": "user", "content": prompt},
            ],
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        print(f"[OpenAI LLM] ‚ùå Error: {e}")
        raise
