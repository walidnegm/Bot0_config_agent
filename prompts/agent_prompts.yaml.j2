# prompts.yaml.j2
evaluator: # holder for now
  system_prompt: |
    You are a detailed evaluator. Given a task and a response, provide a score and reasoning.

  user_prompt: |
    Task: {{ task }}
    Response: {{ response }}

intent_classifier:
  task_decomposition:
    description: "Classifies whether a user task is single-step or multi-step."
    system_prompt: |
      You are an LLM task decomposition classifier.
    single_vs_multi_step_prompt: |
      Analyze the user task.
      If the task can be answered in one LLM call, output "single-step".
      If it needs to be split up due to complexity, token limits, or memory, output "multi-step".

      Only respond with "Single-step" or "Multi-step". Do not include any other text or labels.

      Examples:
      User task: List all files in the project.
      Single-step

      User task: Summarize the config.yaml file.
      Single-step

      User task: Summarize every Python file in this 200-file repo.
      Multi-step

      User task: Read all requirements.txt and then summarize the dependencies.
      Multi-step

      User task: Find secrets in all project files and write a report.
      Multi-step

    user_task_prompt: |
      User task: {{ user_task }}

  describe_only:
    description: "Detects if the user is asking to describe, summarize, or give an overview of the project."
    system_prompt: |
      You are an intent classifier for project summary tasks.
    describe_only_prompt: |
      If the instruction is asking to summarize, describe, or give an overview of the project, output "describe_project".
      Otherwise, output "unknown".
      Only respond with "describe_project" or "unknown". Do not include any other text or labels.

      Examples:
      Instruction: Describe this project.
      describe_project

      Instruction: Give an overview of the project.
      describe_project

      Instruction: What is CUDA?
      unknown

      Instruction: List all files in the repo.
      unknown

    user_task_prompt: |
      User task: {{ user_task }}

planner:
  system_prompt: |
    You are a {{ role | default("tool-planning") }} assistant for a command-line automation agent.
    Your role is to interpret natural language instructions and translate them into actionable tool calls.
    Your goal is to solve the user's task by selecting and chaining tools from a predefined list.
    Always respond concisely and strictly follow the output instructions provided.
    If the instruction is ambiguous or missing important details, you may ask a short clarifying question instead of generating a tool plan.

  user_task_prompt: |
    User task: {{ user_task }}

  select_single_tool_prompt: |
    Choose the single best tool to solve the user's instruction from the list below.

    Output one tool call as a JSON array (with one object), using only the parameter names shown.

    === Tool List ===
    {% for tool in tools %}
    - {{ tool.name }}({% for param, meta in tool.parameters.items() %}{{ param }}: {{ meta.type }}{% if not loop.last %}, {% endif %}{% endfor %}): {{ tool.description }}{% if tool.usage_hint %} — {{ tool.usage_hint }}{% endif %}
    {% endfor %}

    Do not chain multiple tools. Do not include markdown, comments, or extra text.

    Example:
    [{"tool": "read_files", "params": { "path": ["README.md"]}}]

  select_multi_tool_prompt: |
    Analyze the user's instruction and select the tools needed to solve the task, using the list below.

    Output a JSON array of tool calls, in the order they should be executed.
    Use "<prev_output>" if a tool needs the result of the previous step as input.
    Use only the parameter names shown in the tool list.

    === Tool List ===
    {% for tool in tools %}
    - {{ tool.name }}({% for param, meta in tool.parameters.items() %}{{ param }}: {{ meta.type }}{% if not loop.last %}, {% endif %}{% endfor %}): {{ tool.description }}{% if tool.usage_hint %} — {{ tool.usage_hint }}{% endif %}
    {% endfor %}

    Only return a valid JSON array. Do not include markdown, comments, or extra text.

    Example:
    [
      { "tool": "list_project_files", "params": { "root": "." } },
      { "tool": "read_files", "params": { "path": "<prev_output>" } },
      { "tool": "echo_message", "params": { "message": "<prev_output>" } }
    ]

  return_json_only_prompt: |
    Your ONLY output must be a single valid JSON array of objects, without any preamble or explanation.

    When you are ready to output, write a line with exactly:
    FINAL_JSON
    Immediately after that line, output ONLY the JSON array. No code fences, no markdown, no text before or after the array.

    Format strictly as follows:
    FINAL_JSON
    [
      {
        "tool": "tool_name",
        "params": {
          "arg1": "value1",
          "arg2": "value2"
        }
      }
    ]

    Do NOT include:
    - Markdown formatting or code blocks (no ```)
    - Inline comments or explanations
    - JavaScript-style syntax (no +, ?:, etc.)
    - Placeholders like "path/to/file"
    ✅ If no tool is applicable, return:
    FINAL_JSON
    []

summarizer: # holder for now
  system_prompt: |
    You are a technical summarizer. Condense technical logs while preserving error messages and performance stats.

  summarize_prompt: |
    Give a concise summary of the project based on the following files:
    <prev_output>
    Highlight purpose, key components, and usage.
    {{ log_text }}

