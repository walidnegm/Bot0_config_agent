{
  "model_id": "TheBloke/Llama-2-7B-Chat-GPTQ",
  "comment1": "Previous model was meta-llama/Meta-Llama-3-8B-Instruct",
  "comment2": "Switched to GPTQ to reduce memory use"
}
